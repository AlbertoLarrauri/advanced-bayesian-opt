{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:29:13.717773: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-24 18:29:13.717808: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# import IPython\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pyswarm\n",
    "import pandas\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from pyswarm import pso\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda, Layer\n",
    "# from tensorflow.keras import losses\n",
    "# from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error\n",
    "\n",
    "K.set_floatx('float32')\n",
    "\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfk = tfp.math.psd_kernels\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tester.tester import Tester\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lb = [2.2, 1.08, -40.]  # lower bounds of the design variables, i.e. input params for the sut_model\n",
    "ub = [2.8, 1.41, 175.] \n",
    "# log_path = os.path.join('.','2022_02_24_17_12_27_inf_gain')\n",
    "# log_path = os.path.join('.','2022_02_24_19_52_58_inf_gain')\n",
    "log_path = os.path.join('.','Experiments','bay_opt_min'+str(result_idx))\n",
    "\n",
    "\n",
    "save_path= os.path.join('.','BO_MIN_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_samples': 100,\n",
       " 'training_proportion': 0.25,\n",
       " 'log_std_coefficient': 4.0,\n",
       " 'constant_std_coefficient': 10.0,\n",
       " 'seed': 2109997854}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(log_path, 'run_stats.txt')\n",
    "with open(path, 'r') as file:\n",
    "    run_stats = json.load(file)    \n",
    "\n",
    "    \n",
    "num_samples = run_stats['num_samples']\n",
    "training_proportion = run_stats['training_proportion']\n",
    "optimization_proportion = 1. - training_proportion\n",
    "\n",
    "log_std_coefficient = run_stats['log_std_coefficient']\n",
    "constant_std_coefficient = run_stats['constant_std_coefficient']\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(log_path, 'training.npyz')\n",
    "with open(path, 'rb') as file:\n",
    "    training_data = np.load(file)\n",
    "    training_Xs=training_data['points']\n",
    "    training_ys=training_data['values']\n",
    "    norm_training_Xs=training_data['norm_points']\n",
    "    norm_training_ys=training_data['norm_values']\n",
    "    lls_=training_data['loss']\n",
    "    amplitude= training_data['amplitude']\n",
    "    relevances= training_data['relevances']\n",
    "    noise_var= training_data['noise']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llarrauriborroto/Documents/Projects/advanced-bayesian-opt/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join(log_path,'scaler_X.pkl')\n",
    "transform_X = joblib.load(path)\n",
    "path=os.path.join(log_path,'scaler_y.pkl')\n",
    "transform_y = joblib.load(path)\n",
    "\n",
    "\n",
    "norm_ub = transform_X.transform([ub])[0].astype(np.float32)\n",
    "norm_lb = transform_X.transform([lb])[0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.140739  , -1.1259642 , -0.3972631 ],\n",
       "       [ 0.3843126 ,  1.141078  , -0.3972631 ],\n",
       "       [-0.3782126 ,  0.00755684, -0.8276846 ],\n",
       "       [ 0.7909939 , -1.5038043 ,  1.7229613 ],\n",
       "       [ 1.5535191 ,  0.00755684, -0.19002312],\n",
       "       [-1.4965842 , -1.1259642 , -0.8276846 ],\n",
       "       [-1.4965842 ,  0.76323795, -0.8276846 ],\n",
       "       [-1.140739  , -0.74812424, -1.4653461 ],\n",
       "       [ 0.7909939 , -1.1259642 , -0.8276846 ],\n",
       "       [ 1.146839  , -0.74812424, -0.19002312],\n",
       "       [ 0.7909939 ,  1.6133778 ,  1.9620844 ],\n",
       "       [-0.3782126 , -1.1259642 ,  0.44763836],\n",
       "       [-0.7340589 ,  1.141078  ,  0.7664691 ],\n",
       "       [ 1.146839  ,  1.6133778 , -0.19002312],\n",
       "       [-0.3782126 , -0.74812424,  1.0852998 ],\n",
       "       [-1.4965842 ,  1.141078  ,  1.4041306 ],\n",
       "       [ 1.146839  ,  0.00755684, -0.3972631 ],\n",
       "       [ 1.146839  ,  0.76323795, -1.1465153 ],\n",
       "       [ 0.3843126 ,  0.3853968 ,  0.12880762],\n",
       "       [-1.4965842 , -1.5038043 , -0.3972631 ],\n",
       "       [-0.3782126 , -0.74812424,  0.7664691 ],\n",
       "       [-0.7340589 ,  0.00755684, -1.4653461 ],\n",
       "       [ 0.7909939 ,  1.141078  , -0.8276846 ],\n",
       "       [ 0.02846751,  1.141078  ,  1.9620844 ],\n",
       "       [ 1.146839  , -0.37028316,  0.12880762]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_training_Xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.0479727>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = tfk.ExponentiatedQuadratic(amplitude, length_scale=1.0)\n",
    "kernel = tfk.FeatureScaled(kernel, scale_diag=relevances)\n",
    "gp_model = tfd.GaussianProcessRegressionModel(\n",
    "    kernel=kernel,\n",
    "    index_points=[[1.2353002 , -0.7703848 ,  1.1779659]],\n",
    "    observation_index_points=norm_training_Xs,\n",
    "    observations=norm_training_ys,\n",
    "    observation_noise_variance=noise_var,\n",
    "    predictive_noise_variance=0.,\n",
    "    jitter=1e-4)\n",
    "\n",
    "gp_model.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(log_path, 'optimization_rounds.npyz')\n",
    "with open(path, 'rb') as file:\n",
    "    optimization_data = np.load(file)\n",
    "    real_values=optimization_data['values']\n",
    "    real_choices=optimization_data['choices']\n",
    "    mean_regrets=optimization_data['mean_regrets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "values= transform_y.transform(real_values.reshape(-1,1))\n",
    "choices= np.array(transform_X.transform(real_choices), dtype=np.float32)\n",
    "values=np.array(values.flatten(),dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(log_path, 'validation.npyz')\n",
    "\n",
    "\n",
    "with open(filepath, 'rb') as file:\n",
    "    data = np.load(file)\n",
    "    valid_real_Xs=data['points']\n",
    "    valid_real_ys=data['values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1364679 1.1364533 1.1364809 1.1364826 1.1364546 1.136453  1.1364746\n",
      " 1.1364664 1.1364375 1.1366153 1.1366072 1.1366217 1.1366186 1.1366061\n",
      " 1.1365982 1.1366205 1.1366148 1.1366053 1.1367441 1.136754  1.1367435\n",
      " 1.1367403 1.1367362 1.1367447 1.1367383 1.1368902 1.1368879 1.1368802\n",
      " 1.1368752 1.1368766 1.1368825 1.1368804 1.1368675 1.1369122 1.1369243\n",
      " 1.1369307 1.1369127 1.1369225 1.1369193 1.1369181 1.1369164 1.1369104\n",
      " 1.1369476 1.1369559 1.1369513 1.136933  1.1369461 1.1369497 1.1369456\n",
      " 1.1369486 1.1369312 1.1369246 1.1369195 1.1369295 1.1369048 1.1369209\n",
      " 1.1369205 1.1369218 1.1369188 1.1368982 1.1368333 1.1368339 1.1368332\n",
      " 1.1368451 1.1368332 1.1368301 1.1368381 1.1368384 1.1368365 1.1366992\n",
      " 1.136702  1.1366899 1.136702  1.1366932 1.1366885 1.1366879 1.1366869\n",
      " 1.1366874 1.1364846 1.1365002 1.1364875 1.1364605 1.1364737 1.1364778\n",
      " 1.1364824 1.1364766 1.1361785 1.1362098 1.1361988 1.13617   1.1361839\n",
      " 1.1361667 1.1361966 1.1361775 1.1361974 1.1358706 1.1358967 1.1358974\n",
      " 1.135893  1.1358937 1.1358867 1.1358838 1.1358788 1.1358907 1.1363701\n",
      " 1.1363696 1.1363844 1.1363688 1.13637   1.13637   1.1363633 1.1363691\n",
      " 1.1365134 1.1365254 1.1365236 1.1365156 1.1365178 1.1365176 1.1365206\n",
      " 1.1365166 1.1365092 1.1366345 1.1366549 1.1366408 1.1366485 1.1366458\n",
      " 1.136651  1.1366508 1.1366448 1.1366324 1.1367708 1.136772  1.1367645\n",
      " 1.136773  1.1367792 1.1367826 1.1367633 1.1367577 1.1368126 1.1368226\n",
      " 1.1368114 1.1368079 1.1368191 1.1368163 1.1368169 1.1367977 1.1367968\n",
      " 1.1368408 1.1368717 1.1368573 1.1368355 1.1368467 1.1368519 1.1368524\n",
      " 1.1368539 1.1368266 1.1368355 1.13683   1.1368364 1.1368264 1.1368093\n",
      " 1.1368252 1.1368309 1.1368291 1.1368275 1.1367617 1.1367307 1.1367306\n",
      " 1.1367413 1.1367222 1.1367279 1.1367486 1.1367381 1.1367481 1.136598\n",
      " 1.1365975 1.1365749 1.1365924 1.1365819 1.1365865 1.1365885 1.1365783\n",
      " 1.1365858 1.1363891 1.1363996 1.1363741 1.1363599 1.1363733 1.1363835\n",
      " 1.1363758 1.1363771 1.1363758 1.1361016 1.1361247 1.1360934 1.1360782\n",
      " 1.1360792 1.1360682 1.1360897 1.136075  1.1361017 1.1357945 1.135828\n",
      " 1.135809  1.1357985 1.1357969 1.1357746 1.1357819 1.1357685 1.1357956\n",
      " 1.1362542 1.136274  1.1362646 1.1362581 1.1362587 1.136255  1.1362503\n",
      " 1.1362381 1.136397  1.1364    1.136408  1.1364025 1.1363962 1.1364013\n",
      " 1.1363991 1.1363957 1.1363963 1.136527  1.1365285 1.1365263 1.1365286\n",
      " 1.1365311 1.1365235 1.1365222 1.1365193 1.136516  1.1366549 1.136653\n",
      " 1.136654  1.1366506 1.136662  1.1366597 1.1366552 1.1366485 1.1366469\n",
      " 1.1366998 1.1366992 1.1366918 1.1366919 1.1366932 1.1366985 1.1366985\n",
      " 1.1366873 1.1366881 1.1367328 1.1367357 1.136734  1.1367283 1.136716\n",
      " 1.136728  1.1367265 1.1367272 1.136729  1.1367121 1.1367115 1.1367269\n",
      " 1.1367162 1.1367025 1.1366978 1.1366954 1.1367059 1.1367056 1.1366491\n",
      " 1.136632  1.1366224 1.1366472 1.136612  1.1366198 1.1366217 1.1366346\n",
      " 1.1365311 1.1364992 1.1364546 1.1364871 1.1365091 1.136483  1.1364845\n",
      " 1.1364819 1.1364855 1.1362911 1.1362919 1.1362363 1.1362422 1.1363066\n",
      " 1.1362792 1.136278  1.1362778 1.1362792 1.1359961 1.1360141 1.1359782\n",
      " 1.1359494 1.1359597 1.1359819 1.1359855 1.1359912 1.1359856 1.1357136\n",
      " 1.1357433 1.1357045 1.1356769 1.1356728 1.1356958 1.1356913 1.1356989\n",
      " 1.1356877 1.1361388 1.1361376 1.1361536 1.1361547 1.1361487 1.1361421\n",
      " 1.1361322 1.1361254 1.1361241 1.1362835 1.1362857 1.1363051 1.1362919\n",
      " 1.1362978 1.1362835 1.1362821 1.1362797 1.1362779 1.1364206 1.1364133\n",
      " 1.1364255 1.1364248 1.1364115 1.1364033 1.1364057 1.1364062 1.1365482\n",
      " 1.1365429 1.136562  1.1365393 1.1365386 1.1365392 1.1365321 1.1365325\n",
      " 1.1365498 1.1365912 1.1365931 1.1366029 1.1365832 1.1365765 1.13657\n",
      " 1.1365699 1.136569  1.1365739 1.1366317 1.1366225 1.1366172 1.1366173\n",
      " 1.1366097 1.1365893 1.1365879 1.136589  1.1365874 1.1366184 1.1366011\n",
      " 1.1366253 1.1366013 1.1365778 1.1365701 1.1365728 1.136571  1.1365433\n",
      " 1.1365246 1.1365386 1.136545  1.1365259 1.1365141 1.1365088 1.1365085\n",
      " 1.136429  1.1364456 1.1364064 1.1364317 1.1364031 1.1363963 1.1363868\n",
      " 1.1363806 1.1362348 1.1362231 1.1361421 1.1361775 1.1362138 1.1362145\n",
      " 1.1362095 1.1362091 1.1361976 1.1359121 1.1359223 1.1358677 1.1358595\n",
      " 1.1358993 1.1359472 1.1359227 1.1359146 1.1359271 1.1356347 1.1356522\n",
      " 1.135618  1.1355876 1.135604  1.1356575 1.1356337 1.135634  1.1356322\n",
      " 1.1360135 1.1360064 1.1360116 1.1360028 1.1360137 1.1360104 1.1359988\n",
      " 1.1360003 1.1359981 1.1361579 1.13615   1.1361634 1.1361495 1.1361501\n",
      " 1.1361479 1.1361483 1.1361542 1.1361569 1.1362878 1.1362834 1.1362797\n",
      " 1.1362836 1.1362789 1.1362731 1.1362772 1.1362743 1.1362785 1.1364247\n",
      " 1.1364176 1.1364217 1.136404  1.1364238 1.1364157 1.1364063 1.1364182\n",
      " 1.1364081 1.1364492 1.1364622 1.1364771 1.1364477 1.1364529 1.1364691\n",
      " 1.136451  1.1364634 1.136453  1.1365025 1.1364937 1.1365055 1.1364759\n",
      " 1.1364638 1.1364858 1.1364611 1.1364568 1.1364577 1.1365154 1.1364443\n",
      " 1.1364877 1.1365031 1.1364615 1.1364738 1.1364686 1.1364363 1.1364344\n",
      " 1.1364462 1.1363975 1.1364223 1.1364491 1.1364304 1.1363873 1.1364038\n",
      " 1.1363745 1.1363691 1.1363007 1.1363126 1.1362777 1.1363236 1.136333\n",
      " 1.1362813 1.1362768 1.136279  1.1362602 1.1361433 1.1361421 1.1360556\n",
      " 1.1361127 1.1361321 1.136128  1.136092  1.1361058 1.1360924 1.1358396\n",
      " 1.1358323 1.1357802 1.1357954 1.1358371 1.1358509 1.1358533 1.1358434\n",
      " 1.1358411 1.1355512 1.1355448 1.1355139 1.135496  1.1355523 1.1355591\n",
      " 1.135579  1.1355548 1.1358896 1.1359051 1.1358868 1.1358912 1.135893\n",
      " 1.1358982 1.1358955 1.1358991 1.1358875 1.1360354 1.1360456 1.1360364\n",
      " 1.1360382 1.1360364 1.1360474 1.136023  1.1360269 1.1360422 1.1361568\n",
      " 1.1361744 1.1361586 1.1361632 1.1361828 1.136181  1.1361713 1.1361514\n",
      " 1.1361561 1.1363147 1.1363069 1.1362923 1.1363072 1.1363217 1.1363226\n",
      " 1.1363106 1.1363018 1.136341  1.1363826 1.1363499 1.1363392 1.13635\n",
      " 1.1363719 1.1363448 1.1363721 1.136364  1.1363782 1.1363941 1.136419\n",
      " 1.1363422 1.1363542 1.1363752 1.1363711 1.1363745 1.1363968 1.1363723\n",
      " 1.1364241 1.1363789 1.1363508 1.1363405 1.1363767 1.1363394 1.1363335\n",
      " 1.1363522 1.1363275 1.1363332 1.136356  1.1363106 1.1362814 1.136273\n",
      " 1.1362978 1.1362644 1.1362191 1.1361848 1.1361992 1.1362475 1.136223\n",
      " 1.136181  1.136169  1.1361893 1.1361829 1.136015  1.1360184 1.1359851\n",
      " 1.1360458 1.136044  1.136021  1.135998  1.1360077 1.1360042 1.1357554\n",
      " 1.1357588 1.1357044 1.135734  1.1357716 1.1357547 1.1357542 1.1357358\n",
      " 1.1357465 1.135474  1.1354702 1.1354319 1.1354359 1.1354944 1.1354935\n",
      " 1.1354923 1.1354897 1.1354816 1.1357279 1.1357503 1.1357789 1.1357615\n",
      " 1.1357608 1.1357803 1.1357524 1.1357416 1.1357626 1.1358875 1.1358796\n",
      " 1.1359024 1.1359131 1.1359133 1.1359249 1.1359118 1.1358901 1.1358883\n",
      " 1.1360104 1.1360394 1.1360431 1.1360562 1.1360636 1.1360679 1.1360142\n",
      " 1.1361657 1.1361904 1.1361599 1.1361855 1.1362087 1.1362196 1.1362128\n",
      " 1.1362144 1.1361989 1.1362096 1.1362574 1.1362066 1.1362296 1.1362522\n",
      " 1.1362721 1.1362535 1.1362715 1.1362644 1.1362607 1.1363177 1.1362817\n",
      " 1.136227  1.1362427 1.1363112 1.1363109 1.1362871 1.136292  1.1362672\n",
      " 1.1362536 1.136295  1.1362424 1.1362456 1.1362423 1.1362833 1.1362715\n",
      " 1.1362734 1.1362407 1.1361958 1.1362616 1.1362158 1.1362185 1.1361761\n",
      " 1.1362094 1.1362057 1.1362057 1.1361098 1.1360928 1.1361002 1.1361111\n",
      " 1.1361064 1.1360675 1.1360625 1.13609   1.1360884 1.1359148 1.1359051\n",
      " 1.1358664 1.1359432 1.135927  1.1359013 1.1358933 1.135911  1.1359105\n",
      " 1.1356244 1.1356056 1.1356571 1.1356667 1.1356455 1.1356473 1.1356272\n",
      " 1.1356468 1.135357  1.1353703 1.1353412 1.1353681 1.1353958 1.1353748\n",
      " 1.1353837 1.1353672 1.1356059 1.1356169 1.1356795 1.1356353 1.1356282\n",
      " 1.1356579 1.1356269 1.1356192 1.1356505 1.1357546 1.1357493 1.1358081\n",
      " 1.135799  1.1358068 1.1358013 1.1357816 1.1357701 1.1358922 1.1359047\n",
      " 1.1359342 1.1359447 1.1359458 1.1359457 1.1359639 1.1359485 1.135922\n",
      " 1.1360499 1.1361012 1.1360587 1.1360804 1.1361123 1.1361164 1.1361233\n",
      " 1.13611   1.13611   1.1361505 1.1361164 1.1361657 1.1361766 1.136164\n",
      " 1.136174  1.1361772 1.1362262 1.1361591 1.1361581 1.1362278 1.1362267\n",
      " 1.1362183 1.1362116 1.1361841 1.1361659 1.1361794 1.1361331 1.1361756\n",
      " 1.1362014 1.1362121 1.136207  1.1362065 1.1361228 1.1361048 1.1361531\n",
      " 1.1360797 1.1361234 1.1361187 1.1361308 1.1361463 1.1361517 1.1360239\n",
      " 1.1359838 1.1360425 1.1360091 1.1360085 1.1359866 1.1360049 1.1360202\n",
      " 1.1360178 1.1358343 1.1358166 1.1358085 1.1358433 1.1358302 1.1358082\n",
      " 1.135809  1.1358215 1.1358232 1.1355656 1.1355494 1.1355175 1.1355807\n",
      " 1.1355622 1.1355578 1.1355594 1.1355423 1.1355635 1.135283  1.1352694\n",
      " 1.1352575 1.135306  1.1352961 1.1352745 1.1352849 1.1352708 1.1352895\n",
      " 1.1355072 1.1354961 1.1355723 1.1355127 1.1354867 1.1355053 1.1355449\n",
      " 1.1355066 1.1355258 1.135629  1.1356376 1.1357111 1.1356695 1.1356481\n",
      " 1.1356608 1.1357092 1.1356679 1.1356896 1.1357766 1.135825  1.1358446\n",
      " 1.1358352 1.1358109 1.1358151 1.1358438 1.1358535 1.1358318 1.1359413\n",
      " 1.1359906 1.1359608 1.1359767 1.1359984 1.1359906 1.1360046 1.1360178\n",
      " 1.1359937 1.1360123 1.1360523 1.1359984 1.1360098 1.1360598 1.1360639\n",
      " 1.1360756 1.1360561 1.1361005 1.1361161 1.1360409 1.1360496 1.1360584\n",
      " 1.1361308 1.1361293 1.1361265 1.1361097 1.1361053 1.1361185 1.1360519\n",
      " 1.136051  1.1360666 1.1361276 1.1361277 1.1361314 1.1361113 1.136037\n",
      " 1.1360341 1.1360404 1.1360029 1.1360232 1.1360415 1.1360439 1.1360813\n",
      " 1.1360469 1.1359195 1.1358898 1.1359522 1.1358747 1.1359001 1.1359183\n",
      " 1.1359161 1.135933  1.1359156 1.1357374 1.1357033 1.135733  1.1357126\n",
      " 1.1357093 1.1357076 1.1357089 1.1357334 1.1357158 1.1354705 1.1354504\n",
      " 1.1354344 1.1354662 1.1354394 1.1354564 1.1354433 1.1354417 1.1354535\n",
      " 1.135202  1.1351895 1.1351724 1.1352074 1.1351826 1.1351779 1.1351783\n",
      " 1.1351727 1.1351925]\n"
     ]
    }
   ],
   "source": [
    "valid_norm_Xs=np.array(transform_X.transform(valid_real_Xs),dtype=np.float32)\n",
    "valid_norm_Xs\n",
    "print(valid_real_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_norm_Xs=norm_training_Xs.tolist()\n",
    "opt_norm_ys=norm_training_ys.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "75\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(norm_training_Xs.tolist()))\n",
    "print(len(opt_norm_Xs))\n",
    "print(len(opt_norm_ys))\n",
    "print(len(choices))\n",
    "print(len(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sample=[]\n",
    "errs=[]\n",
    "smerrs=[]\n",
    "total_errs=[]\n",
    "\n",
    "pred_points=[]\n",
    "pred_vals=[]\n",
    "\n",
    "for i in range((len(choices))+1):\n",
    "\n",
    "    if i>0:\n",
    "        opt_norm_Xs.append(choices[i-1])\n",
    "        opt_norm_ys.append(values[i-1])\n",
    "\n",
    "    gp_model = tfd.GaussianProcessRegressionModel(\n",
    "        kernel=kernel,\n",
    "        index_points=valid_norm_Xs,\n",
    "        observation_index_points=opt_norm_Xs,\n",
    "        observations=opt_norm_ys,\n",
    "        observation_noise_variance=noise_var,\n",
    "        predictive_noise_variance=0.,\n",
    "        jitter=1e-4)\n",
    "    pred_norm_ys = gp_model.mean().numpy()\n",
    "    pred_real_ys = transform_y.inverse_transform(pred_norm_ys.reshape(-1,1)).flatten()\n",
    "\n",
    "    valid_errs = pred_real_ys - valid_real_ys\n",
    "    total_errs.append(valid_errs)\n",
    "    errs.append(np.amax(valid_errs))\n",
    "    sqvalid_errs = np.square(valid_errs)\n",
    "    smerrs.append(np.sqrt(np.mean(sqvalid_errs)))\n",
    "    max_sample.append(transform_y.inverse_transform(np.array([min(opt_norm_ys)])))\n",
    "    \n",
    "    # Predicted Maximum\n",
    "    \n",
    "    if i%3== 0:\n",
    "        @tf.function(autograph=False, experimental_compile=False)\n",
    "        def eval_model(x):\n",
    "            gp_model = tfd.GaussianProcessRegressionModel(\n",
    "                kernel=kernel,\n",
    "                index_points=[x],\n",
    "                observation_index_points=opt_norm_Xs,\n",
    "                observations=opt_norm_ys,\n",
    "                observation_noise_variance=noise_var,\n",
    "                predictive_noise_variance=0.,\n",
    "                jitter=1e-4)   \n",
    "            \n",
    "            return gp_model.mean()\n",
    "##### GETTING MAX        \n",
    "#         pred_point, pred_value = pso(func=lambda x: -eval_model(np.float32(x)), lb=norm_lb, ub=norm_ub, maxiter=25,\n",
    "#                             debug=False)\n",
    "#         norm_point = transform_X.inverse_transform([pred_point])[0].astype(np.float32)\n",
    "#         norm_val = transform_y.inverse_transform([-pred_value])[0].astype(np.float32)\n",
    "######\n",
    "\n",
    "##### GETTING MIN        \n",
    "#         pred_point, pred_value = pso(func=lambda x: eval_model(np.float32(x)), lb=norm_lb, ub=norm_ub, maxiter=25,\n",
    "#                             debug=False)\n",
    "#         norm_point = transform_X.inverse_transform([pred_point])[0].astype(np.float32)\n",
    "#         norm_val = transform_y.inverse_transform([pred_value])[0].astype(np.float32)\n",
    "######\n",
    "\n",
    "#         pred_points.append(norm_point)\n",
    "#         pred_vals.append(norm_val)\n",
    "        \n",
    "    ##\n",
    "    \n",
    "max_sample=np.array(max_sample)\n",
    "max_sample=max_sample.flatten()\n",
    "\n",
    "\n",
    "######## MAX\n",
    "# filepath = os.path.join(save_path, 'predicted_optimums'+str(result_idx)+'.npyz')\n",
    "# to_save = {\n",
    "#     'values': pred_vals,\n",
    "#     'choices': pred_points,\n",
    "# }\n",
    "\n",
    "####### MIN\n",
    "# filepath = os.path.join(save_path, 'predicted_minimums'+str(result_idx)+'.npyz')\n",
    "# to_save = {\n",
    "#     'values': pred_vals,\n",
    "#     'choices': pred_points,\n",
    "# }\n",
    "\n",
    "\n",
    "# with open(filepath, 'wb') as file:\n",
    "#     np.savez(file, **to_save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(save_path,'max_err'+str(result_idx)+'.npy')\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, errs)\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(errs)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Validation error\")\n",
    "# path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# plt.savefig(path)\n",
    "# plt.show()\n",
    "# plt.savefig('max_loss.pdf',format='pdf',dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(save_path,'smerrs'+str(result_idx)+'.npy')\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, smerrs)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(smerrs)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Validation error\")\n",
    "# # path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# # plt.savefig(path)\n",
    "# # plt.show()\n",
    "# plt.savefig('sme.pdf',format='pdf',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(save_path,'max_sample'+str(result_idx)+'.npy')\n",
    "with open(path, 'wb') as f:\n",
    "    np.save(f, max_sample)\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(max_sample)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Max sample value\")\n",
    "# # path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# # plt.savefig(path)\n",
    "# # plt.show()\n",
    "# plt.savefig('max.pdf',format='pdf',dpi=1200)\n",
    "# max_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_idx=result_idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// run the first 19 cells\n",
       "var n\n",
       "var i;\n",
       "for (n=0; n<10; n++){\n",
       "    for(i=2; i<18; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]);\n",
       "    }\n",
       "\n",
       "    // set the global in the 20th cell:\n",
       "    Jupyter.notebook.execute_cells([18]);\n",
       "\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// run the first 19 cells\n",
    "var n\n",
    "var i;\n",
    "for (n=0; n<10; n++){\n",
    "    for(i=2; i<18; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]);\n",
    "    }\n",
    "\n",
    "    // set the global in the 20th cell:\n",
    "    Jupyter.notebook.execute_cells([18]);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00041616 0.00030696 0.0003227  0.00033832 0.00033414 0.00033414\n",
      " 0.00033414 0.0003618  0.00036728 0.00036991 0.0003705  0.00036991\n",
      " 0.00037122 0.00037193 0.00037277 0.00037217 0.00037158 0.0003711\n",
      " 0.00037086 0.00037026 0.00037003 0.00036991 0.00036943 0.00036824\n",
      " 0.00036407 0.00036049 0.00035846 0.00035727 0.0003556  0.00035524\n",
      " 0.00035453 0.00035441 0.00035429 0.00035453 0.00035453 0.00035465\n",
      " 0.00035429 0.00035417 0.00035322 0.00035322 0.00035322 0.00035298\n",
      " 0.00035286 0.00035286 0.00035286 0.00035286 0.00035262 0.00035262\n",
      " 0.00035262 0.00035226 0.00035214 0.00035214 0.00035214 0.00035167\n",
      " 0.00035155 0.00035167 0.00035155 0.00035167 0.00035167 0.00035107\n",
      " 0.00035107 0.00035107 0.00035155 0.00035107 0.00035131 0.00035119\n",
      " 0.00035119 0.00035107 0.00035119 0.00035381 0.00035357 0.00035369\n",
      " 0.00035381 0.00035381 0.00035381 0.00035381]\n",
      "[0.00041616 0.00030696 0.0003227  0.00033832 0.00033414 0.00033414\n",
      " 0.00033414 0.0003618  0.00036728 0.00036991 0.0003705  0.00036991\n",
      " 0.00037122 0.00037193 0.00037277 0.00037217 0.00037158 0.0003711\n",
      " 0.00037086 0.00037026 0.00037003 0.00036991 0.00036943 0.00036824\n",
      " 0.00036407 0.00036049 0.00035846 0.00035727 0.0003556  0.00035524\n",
      " 0.00035453 0.00035441 0.00035429 0.00035453 0.00035453 0.00035465\n",
      " 0.00035429 0.00035417 0.00035322 0.00035322 0.00035322 0.00035298\n",
      " 0.00035286 0.00035286 0.00035286 0.00035286 0.00035262 0.00035262\n",
      " 0.00035262 0.00035226 0.00035214 0.00035214 0.00035214 0.00035167\n",
      " 0.00035155 0.00035167 0.00035155 0.00035167 0.00035167 0.00035107\n",
      " 0.00035107 0.00035107 0.00035155 0.00035107 0.00035131 0.00035119\n",
      " 0.00035119 0.00035107 0.00035119 0.00035381 0.00035357 0.00035369\n",
      " 0.00035381 0.00035381 0.00035381 0.00035381]\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "filepath= os.path.join('.','BO_MIN_data','max_err4.npy')\n",
    "with open(filepath, 'rb') as file:\n",
    "    values = np.load(file)\n",
    "    \n",
    "print(values)\n",
    "filepath= os.path.join('.','BO_MIN_data','smerrs4.npy')\n",
    "with open(filepath, 'rb') as file:\n",
    "    values = np.load(file)\n",
    "\n",
    "print(values)\n",
    "\n",
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00015533 0.00016367 0.00016403 0.00022602 0.00021946 0.00022113\n",
      " 0.00023079 0.0002315  0.00023198 0.00022984 0.00023329 0.00024068\n",
      " 0.00024199 0.0002408  0.00024056 0.00023651 0.00023973 0.00023687\n",
      " 0.00023544 0.00023437 0.00022531 0.00022471 0.00022435 0.00022399\n",
      " 0.00022244 0.00022173 0.00022101 0.00022089 0.00022018 0.00021935\n",
      " 0.00021958 0.00021911 0.00021887 0.00021875 0.00021768 0.00021756\n",
      " 0.00021911 0.00021887 0.00021291 0.00021255 0.00021267 0.00021243\n",
      " 0.00021231 0.00020611 0.00020325 0.00020015 0.00019681 0.00020349\n",
      " 0.00020349 0.00020361 0.00020206 0.0002017  0.00020087 0.00019979\n",
      " 0.0001992  0.00019836 0.00019741 0.00019777 0.00019753 0.00019407\n",
      " 0.00019348 0.00019348 0.00019193 0.00019038 0.00018954 0.00018883\n",
      " 0.00018847 0.00018859 0.00018811 0.00018787 0.00018728 0.00018704\n",
      " 0.00018597 0.00018513 0.00018501 0.00018847]\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "filepath= os.path.join('.','BO_data','max_err3.npy')\n",
    "with open(filepath, 'rb') as file:\n",
    "    values = np.load(file)\n",
    "\n",
    "\n",
    "print(values)\n",
    "\n",
    "print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path = os.path.join('.','Uniform_data')\n",
    "filepath = os.path.join(log_path,'samples.npyz')\n",
    "\n",
    "with open(filepath, 'rb') as file:\n",
    "    data = np.load(file)\n",
    "    values = data['values']\n",
    "    \n",
    "len(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.13549127, 1.13559665, 1.13633011, 1.13604062, 1.13621663,\n",
       "       1.13674894, 1.13580586, 1.13576565, 1.13627605, 1.13572132,\n",
       "       1.1357574 , 1.13580697, 1.13670155, 1.13669186, 1.13616053,\n",
       "       1.13664467, 1.13549922, 1.13605184, 1.13587973, 1.13588408,\n",
       "       1.13632889, 1.13676279, 1.13667152, 1.13597394, 1.13634622])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    maxs=[]\n",
    "    mins=[]\n",
    "    start=100*i\n",
    "    for j in range(25,101,3):\n",
    "        opt=max(values[start:start+j+1])\n",
    "        maxs.append(opt)\n",
    "        opt=min(values[start:start+j+1])\n",
    "        mins.append(opt)\n",
    "        \n",
    "    path= os.path.join(log_path,'maximums'+str(i)+'.npy')\n",
    "    with open(path, 'wb') as file:\n",
    "        np.save(file,maxs)\n",
    "    \n",
    "    path= os.path.join(log_path,'minimums'+str(i)+'.npy')\n",
    "    with open(path, 'wb') as file:\n",
    "        np.save(file,mins)\n",
    "        \n",
    "        \n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
