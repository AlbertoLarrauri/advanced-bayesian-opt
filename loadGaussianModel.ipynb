{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-14 12:17:18.679738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-14 12:17:18.679768: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# import IPython\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pyswarm\n",
    "import pandas\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# from mpl_toolkits.mplot3d import Axes3D\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from pyswarm import pso\n",
    "\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "# from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Lambda, Layer\n",
    "# from tensorflow.keras import losses\n",
    "# from keras.utils.vis_utils import plot_model, model_to_dot\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score, mean_absolute_error, median_absolute_error\n",
    "\n",
    "K.set_floatx('float32')\n",
    "\n",
    "tfb = tfp.bijectors\n",
    "tfd = tfp.distributions\n",
    "tfk = tfp.math.psd_kernels\n",
    "\n",
    "tf.enable_v2_behavior()\n",
    "\n",
    "from tester.tester import Tester\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_idx=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lb = [2.2, 1.08, -40.]  # lower bounds of the design variables, i.e. input params for the sut_model\n",
    "ub = [2.8, 1.41, 175.] \n",
    "# log_path = os.path.join('.','2022_02_24_17_12_27_inf_gain')\n",
    "# log_path = os.path.join('.','2022_02_24_19_52_58_inf_gain')\n",
    "log_path = os.path.join('.','Experiments','inf_gain'+str(result_idx))\n",
    "\n",
    "\n",
    "save_path= os.path.join('.','IG_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_samples': 100,\n",
       " 'training_proportion': 0.25,\n",
       " 'log_std_coefficient': 4.0,\n",
       " 'constant_std_coefficient': 10.0}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(log_path, 'run_stats.txt')\n",
    "with open(path, 'r') as file:\n",
    "    run_stats = json.load(file)    \n",
    "\n",
    "    \n",
    "num_samples = run_stats['num_samples']\n",
    "training_proportion = run_stats['training_proportion']\n",
    "optimization_proportion = 1. - training_proportion\n",
    "\n",
    "log_std_coefficient = run_stats['log_std_coefficient']\n",
    "constant_std_coefficient = run_stats['constant_std_coefficient']\n",
    "\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(log_path, 'training.npyz')\n",
    "with open(path, 'rb') as file:\n",
    "    training_data = np.load(file)\n",
    "    training_Xs=training_data['points']\n",
    "    training_ys=training_data['values']\n",
    "    norm_training_Xs=training_data['norm_points']\n",
    "    norm_training_ys=training_data['norm_values']\n",
    "    lls_=training_data['loss']\n",
    "    amplitude= training_data['amplitude']\n",
    "    relevances= training_data['relevances']\n",
    "    noise_var= training_data['noise']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llarrauriborroto/Documents/Projects/advanced-bayesian-opt/lib/python3.8/site-packages/sklearn/base.py:313: UserWarning: Trying to unpickle estimator StandardScaler from version 0.21.2 when using version 0.22. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join(log_path,'scaler_X.pkl')\n",
    "transform_X = joblib.load(path)\n",
    "path=os.path.join(log_path,'scaler_y.pkl')\n",
    "transform_y = joblib.load(path)\n",
    "\n",
    "\n",
    "norm_ub = transform_X.transform([ub])[0].astype(np.float32)\n",
    "norm_lb = transform_X.transform([lb])[0].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1625067 , -0.6983937 ,  1.1239966 ],\n",
       "       [-1.0833786 , -0.332742  , -0.7049146 ],\n",
       "       [ 1.3542231 , -1.0640442 , -0.96618766],\n",
       "       [ 1.3542231 ,  1.5869246 ,  1.3852696 ],\n",
       "       [-0.27084422,  0.76421076,  0.07890446],\n",
       "       [ 0.5416888 ,  0.39855912, -0.96618766],\n",
       "       [ 0.5416888 ,  0.03290855, -1.2274607 ],\n",
       "       [ 0.1625067 ,  1.1298614 , -0.35219604],\n",
       "       [ 0.975041  ,  1.5869246 , -0.96618766],\n",
       "       [-1.0833786 ,  1.1298614 , -1.2274607 ],\n",
       "       [ 0.975041  , -1.4296948 ,  0.3401775 ],\n",
       "       [-1.0833786 ,  0.03290855,  1.3852696 ],\n",
       "       [-1.0833786 , -1.4296948 , -0.18236858],\n",
       "       [-0.27084422, -0.6983937 , -0.7049146 ],\n",
       "       [-0.6500276 , -1.4296948 , -0.96618766],\n",
       "       [ 1.3542231 ,  0.76421076,  1.1239966 ],\n",
       "       [ 0.1625067 , -0.332742  , -0.35219604],\n",
       "       [-0.6500276 ,  0.39855912,  1.3852696 ],\n",
       "       [ 0.975041  , -1.4296948 , -1.2274607 ],\n",
       "       [ 1.3542231 ,  0.76421076,  1.5812244 ],\n",
       "       [-1.4625605 , -1.0640442 , -0.18236858],\n",
       "       [-1.0833786 ,  0.76421076,  0.60145056],\n",
       "       [-1.4625605 , -0.332742  ,  0.8627236 ],\n",
       "       [ 1.3542231 ,  1.5869246 , -1.2274607 ],\n",
       "       [-1.0833786 , -0.6983937 ,  1.3852696 ]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_training_Xs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.0904675>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = tfk.ExponentiatedQuadratic(amplitude, length_scale=1.0)\n",
    "kernel = tfk.FeatureScaled(kernel, scale_diag=relevances)\n",
    "gp_model = tfd.GaussianProcessRegressionModel(\n",
    "    kernel=kernel,\n",
    "    index_points=[[1.2353002 , -0.7703848 ,  1.1779659]],\n",
    "    observation_index_points=norm_training_Xs,\n",
    "    observations=norm_training_ys,\n",
    "    observation_noise_variance=noise_var,\n",
    "    predictive_noise_variance=0.,\n",
    "    jitter=1e-4)\n",
    "\n",
    "gp_model.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(log_path, 'optimization_rounds.npyz')\n",
    "with open(path, 'rb') as file:\n",
    "    optimization_data = np.load(file)\n",
    "    real_values=optimization_data['values']\n",
    "    real_choices=optimization_data['choices']\n",
    "    mean_regrets=optimization_data['mean_regrets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "values= transform_y.transform(real_values.reshape(-1,1))\n",
    "choices= np.array(transform_X.transform(real_choices), dtype=np.float32)\n",
    "values=np.array(values.flatten(),dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(log_path, 'validation.npyz')\n",
    "\n",
    "\n",
    "with open(filepath, 'rb') as file:\n",
    "    data = np.load(file)\n",
    "    valid_real_Xs=data['points']\n",
    "    valid_real_ys=data['values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1364679 1.1364533 1.1364809 1.1364826 1.1364546 1.136453  1.1364746\n",
      " 1.1364664 1.1364375 1.1366153 1.1366072 1.1366217 1.1366186 1.1366061\n",
      " 1.1365982 1.1366205 1.1366148 1.1366053 1.1367441 1.1367519 1.136754\n",
      " 1.1367435 1.1367403 1.1367362 1.1367514 1.1367447 1.1367383 1.136869\n",
      " 1.1368902 1.1368879 1.1368802 1.1368752 1.1368766 1.1368825 1.1368804\n",
      " 1.1368675 1.1369122 1.1369307 1.1369127 1.1369225 1.1369193 1.1369181\n",
      " 1.1369164 1.1369104 1.1369476 1.1369559 1.1369513 1.136933  1.1369461\n",
      " 1.1369497 1.1369456 1.1369486 1.1369312 1.1369246 1.1369195 1.1369295\n",
      " 1.1369048 1.1369209 1.1369205 1.1369218 1.1369188 1.1368982 1.1368333\n",
      " 1.1368339 1.1368332 1.1368451 1.1368332 1.1368301 1.1368381 1.1368384\n",
      " 1.1368365 1.1366992 1.136702  1.1366899 1.1366932 1.1366885 1.1366879\n",
      " 1.1366869 1.1366874 1.1364846 1.1365002 1.1364875 1.1364605 1.1364737\n",
      " 1.1364778 1.1364824 1.1364878 1.1364766 1.1361785 1.1362098 1.1361988\n",
      " 1.13617   1.1361839 1.1361667 1.1361966 1.1361775 1.1361974 1.1358706\n",
      " 1.1358967 1.1358974 1.135893  1.1358937 1.1358867 1.1358838 1.1358788\n",
      " 1.1358907 1.1363701 1.1363696 1.1363951 1.1363844 1.1363688 1.13637\n",
      " 1.13637   1.1363691 1.1365134 1.1365254 1.1365236 1.1365156 1.1365178\n",
      " 1.1365176 1.1365206 1.1365166 1.1365092 1.1366345 1.1366549 1.1366408\n",
      " 1.1366458 1.136651  1.1366508 1.1366448 1.1366324 1.1367708 1.1367778\n",
      " 1.136772  1.1367645 1.136773  1.1367792 1.1367826 1.1367633 1.1367577\n",
      " 1.1368226 1.1368114 1.1368079 1.1368191 1.1368163 1.1368169 1.1367977\n",
      " 1.1367968 1.1368408 1.1368717 1.1368573 1.1368355 1.1368467 1.1368519\n",
      " 1.1368524 1.1368539 1.1368266 1.1368355 1.13683   1.1368364 1.1368264\n",
      " 1.1368093 1.1368252 1.1368309 1.1368291 1.1368275 1.1367617 1.1367307\n",
      " 1.1367306 1.1367413 1.1367222 1.1367279 1.1367381 1.1367481 1.136598\n",
      " 1.1365975 1.1365749 1.1365924 1.1365819 1.1365865 1.1365885 1.1365783\n",
      " 1.1365858 1.1363891 1.1363996 1.1363741 1.1363599 1.1363733 1.1363835\n",
      " 1.1363758 1.1363771 1.1363758 1.1361016 1.1361247 1.1360782 1.1360682\n",
      " 1.1360897 1.136075  1.1361017 1.1357945 1.135828  1.135809  1.1357985\n",
      " 1.1357969 1.1357746 1.1357819 1.1357685 1.1357956 1.1362542 1.136274\n",
      " 1.1362646 1.1362581 1.1362536 1.1362587 1.136255  1.1362503 1.1362381\n",
      " 1.1364    1.136408  1.1364025 1.1363962 1.1364013 1.1363991 1.1363957\n",
      " 1.1363963 1.136527  1.1365285 1.1365263 1.1365286 1.1365311 1.1365235\n",
      " 1.1365222 1.1365193 1.136516  1.1366549 1.136653  1.136654  1.1366506\n",
      " 1.136662  1.1366597 1.1366552 1.1366485 1.1366469 1.1366998 1.1366992\n",
      " 1.1366918 1.1366919 1.1366932 1.1366985 1.1366985 1.1366873 1.1366881\n",
      " 1.1367328 1.1367357 1.136734  1.1367283 1.136716  1.136728  1.1367265\n",
      " 1.1367272 1.136729  1.1367121 1.1367115 1.1367269 1.1367162 1.1367025\n",
      " 1.1366978 1.1366954 1.1367059 1.1367056 1.1366491 1.136632  1.1366224\n",
      " 1.1366472 1.136612  1.1366198 1.1366217 1.1366224 1.1366346 1.1365311\n",
      " 1.1364992 1.1364546 1.1364871 1.1365091 1.136483  1.1364845 1.1364819\n",
      " 1.1364855 1.1362911 1.1362919 1.1362363 1.1362422 1.1363066 1.1362792\n",
      " 1.136278  1.1362778 1.1362792 1.1359961 1.1360141 1.1359782 1.1359494\n",
      " 1.1359597 1.1359855 1.1359912 1.1359856 1.1357136 1.1357433 1.1357045\n",
      " 1.1356769 1.1356728 1.1356958 1.1356913 1.1356989 1.1356877 1.1361388\n",
      " 1.1361376 1.1361536 1.1361547 1.1361487 1.1361421 1.1361322 1.1361254\n",
      " 1.1361241 1.1362835 1.1362857 1.1363051 1.1362919 1.1362978 1.1362835\n",
      " 1.1362821 1.1362797 1.1362779 1.1364206 1.1364133 1.1364248 1.1364117\n",
      " 1.1364115 1.1364033 1.1364057 1.1364062 1.1365482 1.1365429 1.136562\n",
      " 1.1365393 1.1365386 1.1365392 1.1365321 1.1365325 1.1365498 1.1365912\n",
      " 1.1365931 1.1366029 1.1365832 1.1365765 1.13657   1.1365699 1.136569\n",
      " 1.1365739 1.1366317 1.1366225 1.1366172 1.1366173 1.1366097 1.1365893\n",
      " 1.136589  1.1365874 1.1366184 1.1365893 1.1366011 1.1366253 1.1366013\n",
      " 1.1365778 1.1365701 1.1365728 1.136571  1.1365433 1.1365246 1.1365384\n",
      " 1.1365386 1.136545  1.1365259 1.1365141 1.1365088 1.1365085 1.136429\n",
      " 1.1364456 1.1363639 1.1364064 1.1364317 1.1364031 1.1363963 1.1363868\n",
      " 1.1363806 1.1362348 1.1362231 1.1361421 1.1361775 1.1362138 1.1362145\n",
      " 1.1362095 1.1362091 1.1361976 1.1359121 1.1359223 1.1358677 1.1358595\n",
      " 1.1358993 1.1359472 1.1359227 1.1359146 1.1359271 1.1356347 1.1356522\n",
      " 1.135618  1.1355876 1.135604  1.1356575 1.1356337 1.135634  1.1356322\n",
      " 1.1360135 1.1360064 1.1360116 1.1360028 1.1360137 1.1360104 1.1359988\n",
      " 1.1360003 1.1359981 1.1361579 1.13615   1.1361634 1.1361495 1.1361501\n",
      " 1.1361479 1.1361483 1.1361542 1.1361569 1.1362878 1.1362834 1.1362797\n",
      " 1.1362836 1.1362789 1.1362731 1.1362772 1.1362743 1.1362785 1.1364247\n",
      " 1.1364176 1.1364217 1.1364238 1.1364157 1.1364063 1.1364081 1.1364492\n",
      " 1.1364622 1.1364771 1.1364477 1.1364529 1.1364691 1.136451  1.1364634\n",
      " 1.136453  1.1365025 1.1364937 1.1365055 1.1364759 1.1364638 1.1364858\n",
      " 1.1364611 1.1364568 1.1364577 1.1365154 1.1364443 1.1364877 1.1365031\n",
      " 1.1364615 1.1364738 1.1364686 1.1364363 1.1364344 1.1364462 1.1363975\n",
      " 1.1364223 1.1364491 1.1364304 1.1363873 1.1364038 1.1363745 1.1363691\n",
      " 1.1363007 1.1363126 1.1362777 1.1363236 1.136333  1.1362813 1.1362768\n",
      " 1.136279  1.1362602 1.1361433 1.1361421 1.1361127 1.1361321 1.136128\n",
      " 1.136092  1.1361058 1.1360924 1.1358396 1.1358323 1.1357802 1.1357954\n",
      " 1.1358371 1.1358509 1.1358533 1.1358434 1.1358411 1.1355512 1.1355448\n",
      " 1.1355139 1.135496  1.1355523 1.1355591 1.135579  1.1355704 1.1355548\n",
      " 1.1358896 1.1359051 1.1358868 1.1358912 1.1358982 1.1358955 1.1358991\n",
      " 1.1358875 1.1360354 1.1360456 1.1360364 1.1360382 1.1360364 1.136023\n",
      " 1.1360269 1.1360422 1.1361568 1.1361744 1.1361586 1.1361632 1.1361828\n",
      " 1.136181  1.1361713 1.1361514 1.1361561 1.1363147 1.1363069 1.1362923\n",
      " 1.1363072 1.1363217 1.1363226 1.1363106 1.1363182 1.1363018 1.136341\n",
      " 1.1363826 1.1363499 1.1363392 1.13635   1.1363719 1.1363448 1.1363721\n",
      " 1.136364  1.1363782 1.1363941 1.136419  1.1363422 1.1363542 1.1363972\n",
      " 1.1363752 1.1363711 1.1363745 1.1363968 1.1363723 1.1364241 1.1363789\n",
      " 1.1363508 1.1363405 1.1363767 1.1363394 1.1363335 1.1363522 1.1363275\n",
      " 1.1363332 1.136356  1.1363106 1.1362814 1.136273  1.1362978 1.1362644\n",
      " 1.1362191 1.1361848 1.1361992 1.1362475 1.136223  1.136181  1.136169\n",
      " 1.1361893 1.1361829 1.136015  1.1360184 1.1359851 1.1360458 1.136044\n",
      " 1.136021  1.135998  1.1360077 1.1360042 1.1357554 1.1357588 1.1357044\n",
      " 1.135734  1.1357716 1.1357547 1.1357542 1.1357358 1.1357465 1.135474\n",
      " 1.1354702 1.1354319 1.1354359 1.1354944 1.1354935 1.1354923 1.1354897\n",
      " 1.1354816 1.1357503 1.1357789 1.1357615 1.1357608 1.1357803 1.1357524\n",
      " 1.1357416 1.1357626 1.1358875 1.1358796 1.1359024 1.1359131 1.1359133\n",
      " 1.1359249 1.1359118 1.1358901 1.1360104 1.1360276 1.1360394 1.1360431\n",
      " 1.1360562 1.1360636 1.1360679 1.1360333 1.1360142 1.1361657 1.1361904\n",
      " 1.1361599 1.1361855 1.1362087 1.1362196 1.1362128 1.1362144 1.1361989\n",
      " 1.1362096 1.1362574 1.1362066 1.1362296 1.1362522 1.1362721 1.1362535\n",
      " 1.1362715 1.1362644 1.1362607 1.1363177 1.1362817 1.136227  1.1362427\n",
      " 1.1363112 1.1363109 1.1362871 1.136292  1.1362536 1.136295  1.1362424\n",
      " 1.1362456 1.1362423 1.1362833 1.1362715 1.1362734 1.1362407 1.1361958\n",
      " 1.1362616 1.1362158 1.1362185 1.1361761 1.1362094 1.1362057 1.1362057\n",
      " 1.1361098 1.1360928 1.1361002 1.1361111 1.1361064 1.1360675 1.1360625\n",
      " 1.13609   1.1360884 1.1359148 1.1359051 1.1358664 1.1359432 1.135927\n",
      " 1.1359013 1.1358933 1.135911  1.1359105 1.135629  1.1356244 1.1356056\n",
      " 1.1356571 1.1356667 1.1356455 1.1356473 1.1356272 1.1356468 1.135357\n",
      " 1.1353703 1.1353412 1.1353681 1.1353958 1.1353748 1.1353837 1.1353672\n",
      " 1.1353788 1.1356059 1.1356169 1.1356795 1.1356353 1.1356282 1.1356579\n",
      " 1.1356269 1.1356192 1.1357546 1.1358081 1.135799  1.1358068 1.1358013\n",
      " 1.1358247 1.1357816 1.1357701 1.1358922 1.1359047 1.1359342 1.1359447\n",
      " 1.1359458 1.1359457 1.1359639 1.1359485 1.135922  1.1360499 1.1361012\n",
      " 1.1360587 1.1360804 1.136101  1.1361123 1.1361164 1.1361233 1.13611\n",
      " 1.13611   1.1361505 1.1361009 1.1361164 1.1361657 1.1361766 1.136164\n",
      " 1.136174  1.1361717 1.1361772 1.1362262 1.1361591 1.1361635 1.1361581\n",
      " 1.1362278 1.1362267 1.1362183 1.1362116 1.1361841 1.1361659 1.1361794\n",
      " 1.1361331 1.1361756 1.1362014 1.1362121 1.136207  1.1362065 1.1361228\n",
      " 1.1361048 1.1361531 1.1360797 1.1361234 1.1361187 1.1361308 1.1361463\n",
      " 1.1361517 1.1360239 1.1359838 1.1360425 1.1360091 1.1360085 1.1359866\n",
      " 1.1360049 1.1360202 1.1360178 1.1358343 1.1358166 1.1358085 1.1358433\n",
      " 1.1358302 1.1358082 1.1358215 1.1358232 1.1355656 1.1355494 1.1355175\n",
      " 1.1355807 1.1355622 1.1355578 1.1355594 1.1355423 1.135283  1.1352694\n",
      " 1.1352575 1.135306  1.1352961 1.1352745 1.1352708 1.1352895 1.1355072\n",
      " 1.1354961 1.1355723 1.1355127 1.1354867 1.1355053 1.1355449 1.1355066\n",
      " 1.1355258 1.135629  1.1356376 1.1357111 1.1356695 1.1356481 1.1356608\n",
      " 1.1357092 1.1356679 1.1356896 1.1357766 1.135825  1.1358446 1.1358352\n",
      " 1.1358109 1.1358151 1.1358438 1.1358535 1.1358318 1.1359413 1.1359906\n",
      " 1.1359608 1.1359767 1.1359984 1.1359906 1.1360046 1.1360178 1.1359937\n",
      " 1.1360123 1.1360523 1.1359984 1.1360098 1.1360531 1.1360598 1.1360639\n",
      " 1.1360756 1.1360561 1.1361005 1.1361161 1.1360409 1.1360496 1.1360584\n",
      " 1.1361308 1.1361293 1.1361265 1.1361097 1.1361053 1.1361185 1.1360519\n",
      " 1.136051  1.1360666 1.1361276 1.1361277 1.1361314 1.1361113 1.136037\n",
      " 1.1360341 1.1360404 1.1360029 1.1360232 1.1360415 1.1360439 1.1360813\n",
      " 1.1360469 1.1359195 1.1358898 1.1359522 1.1358747 1.1359001 1.1359183\n",
      " 1.1359161 1.135933  1.1359156 1.1357374 1.1357033 1.135733  1.1357126\n",
      " 1.1357093 1.1357076 1.1357089 1.1357334 1.1357158 1.1354705 1.1354504\n",
      " 1.1354344 1.1354662 1.1354394 1.1354564 1.1354433 1.1354417 1.1354535\n",
      " 1.135202  1.1351895 1.1351724 1.1352074 1.1351826 1.1351779 1.1351783\n",
      " 1.1351727 1.1351925]\n"
     ]
    }
   ],
   "source": [
    "valid_norm_Xs=np.array(transform_X.transform(valid_real_Xs),dtype=np.float32)\n",
    "valid_norm_Xs\n",
    "print(valid_real_ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_norm_Xs=norm_training_Xs.tolist()\n",
    "opt_norm_ys=norm_training_ys.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "25\n",
      "25\n",
      "75\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(norm_training_Xs.tolist()))\n",
    "print(len(opt_norm_Xs))\n",
    "print(len(opt_norm_ys))\n",
    "print(len(choices))\n",
    "print(len(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n",
      "Stopping search: maximum iterations reached --> 25\n"
     ]
    }
   ],
   "source": [
    "max_sample=[]\n",
    "errs=[]\n",
    "smerrs=[]\n",
    "total_errs=[]\n",
    "\n",
    "pred_points=[]\n",
    "pred_vals=[]\n",
    "\n",
    "for i in range((len(choices))+1):\n",
    "\n",
    "    if i>0:\n",
    "        opt_norm_Xs.append(choices[i-1])\n",
    "        opt_norm_ys.append(values[i-1])\n",
    "\n",
    "    gp_model = tfd.GaussianProcessRegressionModel(\n",
    "        kernel=kernel,\n",
    "        index_points=valid_norm_Xs,\n",
    "        observation_index_points=opt_norm_Xs,\n",
    "        observations=opt_norm_ys,\n",
    "        observation_noise_variance=noise_var,\n",
    "        predictive_noise_variance=0.,\n",
    "        jitter=1e-4)\n",
    "    pred_norm_ys = gp_model.mean().numpy()\n",
    "    pred_real_ys = transform_y.inverse_transform(pred_norm_ys.reshape(-1,1)).flatten()\n",
    "\n",
    "    valid_errs = pred_real_ys - valid_real_ys\n",
    "    total_errs.append(valid_errs)\n",
    "    errs.append(np.amax(valid_errs))\n",
    "    sqvalid_errs = np.square(valid_errs)\n",
    "    smerrs.append(np.sqrt(np.mean(sqvalid_errs)))\n",
    "    max_sample.append(transform_y.inverse_transform(np.array([max(opt_norm_ys)])))\n",
    "    \n",
    "    # Predicted Maximum\n",
    "    \n",
    "    if i%3== 0:\n",
    "        @tf.function(autograph=False, experimental_compile=False)\n",
    "        def eval_model(x):\n",
    "            gp_model = tfd.GaussianProcessRegressionModel(\n",
    "                kernel=kernel,\n",
    "                index_points=[x],\n",
    "                observation_index_points=opt_norm_Xs,\n",
    "                observations=opt_norm_ys,\n",
    "                observation_noise_variance=noise_var,\n",
    "                predictive_noise_variance=0.,\n",
    "                jitter=1e-4)   \n",
    "            \n",
    "            return gp_model.mean()\n",
    "##### GETTING MAX        \n",
    "#         pred_point, pred_value = pso(func=lambda x: -eval_model(np.float32(x)), lb=norm_lb, ub=norm_ub, maxiter=25,\n",
    "#                             debug=False)\n",
    "#         norm_point = transform_X.inverse_transform([pred_point])[0].astype(np.float32)\n",
    "#         norm_val = transform_y.inverse_transform([-pred_value])[0].astype(np.float32)\n",
    "######\n",
    "\n",
    "##### GETTING MIN        \n",
    "        pred_point, pred_value = pso(func=lambda x: eval_model(np.float32(x)), lb=norm_lb, ub=norm_ub, maxiter=25,\n",
    "                            debug=False)\n",
    "        norm_point = transform_X.inverse_transform([pred_point])[0].astype(np.float32)\n",
    "        norm_val = transform_y.inverse_transform([pred_value])[0].astype(np.float32)\n",
    "######\n",
    "\n",
    "        pred_points.append(norm_point)\n",
    "        pred_vals.append(norm_val)\n",
    "        \n",
    "    ##\n",
    "    \n",
    "max_sample=np.array(max_sample)\n",
    "max_sample=max_sample.flatten()\n",
    "\n",
    "\n",
    "######## MAX\n",
    "# filepath = os.path.join(save_path, 'predicted_optimums'+str(result_idx)+'.npyz')\n",
    "# to_save = {\n",
    "#     'values': pred_vals,\n",
    "#     'choices': pred_points,\n",
    "# }\n",
    "\n",
    "####### MIN\n",
    "filepath = os.path.join(save_path, 'predicted_minimums'+str(result_idx)+'.npyz')\n",
    "to_save = {\n",
    "    'values': pred_vals,\n",
    "    'choices': pred_points,\n",
    "}\n",
    "\n",
    "\n",
    "with open(filepath, 'wb') as file:\n",
    "    np.savez(file, **to_save)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(save_path,'max_err'+str(result_idx)+'.npy')\n",
    "# with open(path, 'wb') as f:\n",
    "#     np.save(f, errs)\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(errs)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Validation error\")\n",
    "# # path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# # plt.savefig(path)\n",
    "# # plt.show()\n",
    "# plt.savefig('max_loss.pdf',format='pdf',dpi=1200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(save_path,'smerrs'+str(result_idx)+'.npy')\n",
    "# with open(path, 'wb') as f:\n",
    "#     np.save(f, errs)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(smerrs)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Validation error\")\n",
    "# # path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# # plt.savefig(path)\n",
    "# # plt.show()\n",
    "# plt.savefig('sme.pdf',format='pdf',dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = os.path.join(save_path,'max_sample'+str(result_idx)+'.npy')\n",
    "# with open(path, 'wb') as f:\n",
    "#     np.save(f, max_sample)\n",
    "\n",
    "# plt.figure(figsize=(12, 4))\n",
    "# plt.plot(max_sample)\n",
    "# plt.xlabel(\"Optimization iteration\")\n",
    "# plt.ylabel(\"Max sample value\")\n",
    "# # path = os.path.join(log_path, 'mean_regrets.png')\n",
    "# # plt.savefig(path)\n",
    "# # plt.show()\n",
    "# plt.savefig('max.pdf',format='pdf',dpi=1200)\n",
    "# max_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_idx=result_idx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "// run the first 19 cells\n",
       "var n\n",
       "var i;\n",
       "for (n=0; n<10; n++){\n",
       "    for(i=2; i<18; i++) {\n",
       "        Jupyter.notebook.execute_cells([i]);\n",
       "    }\n",
       "\n",
       "    // set the global in the 20th cell:\n",
       "    Jupyter.notebook.execute_cells([18]);\n",
       "\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "// run the first 19 cells\n",
    "var n\n",
    "var i;\n",
    "for (n=0; n<10; n++){\n",
    "    for(i=2; i<18; i++) {\n",
    "        Jupyter.notebook.execute_cells([i]);\n",
    "    }\n",
    "\n",
    "    // set the global in the 20th cell:\n",
    "    Jupyter.notebook.execute_cells([18]);\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1370226 1.1369528 1.1369511 1.13695   1.136952  1.1369522 1.1369481\n",
      " 1.1369532 1.1369531 1.1369505 1.1369528 1.1369507 1.1369525 1.1369518\n",
      " 1.136952  1.136952  1.136952  1.136952  1.1369522 1.136953  1.1369523\n",
      " 1.1369535 1.1369534 1.1369522 1.1369535 1.1369524]\n",
      "[[ 2.2        1.41      64.049995 ]\n",
      " [ 2.2        1.3322372 60.510517 ]\n",
      " [ 2.2        1.3311702 60.00185  ]\n",
      " [ 2.2        1.08      63.353313 ]\n",
      " [ 2.2        1.3328456 61.992718 ]\n",
      " [ 2.2        1.330387  62.099266 ]\n",
      " [ 2.2        1.08      63.475464 ]\n",
      " [ 2.2        1.3341663 61.0695   ]\n",
      " [ 2.2        1.3364384 60.97415  ]\n",
      " [ 2.2        1.1072025 64.52208  ]\n",
      " [ 2.2        1.3431572 60.501053 ]\n",
      " [ 2.2        1.1086153 63.922585 ]\n",
      " [ 2.2        1.3397785 61.2733   ]\n",
      " [ 2.2        1.1146424 63.6277   ]\n",
      " [ 2.2        1.3419793 61.46114  ]\n",
      " [ 2.2        1.1129096 62.693    ]\n",
      " [ 2.2        1.3419278 61.57104  ]\n",
      " [ 2.2        1.3388362 62.221718 ]\n",
      " [ 2.2        1.3395972 61.854694 ]\n",
      " [ 2.2        1.1116929 61.959324 ]\n",
      " [ 2.2        1.3402332 61.645985 ]\n",
      " [ 2.2        1.1174301 61.6623   ]\n",
      " [ 2.2        1.1168717 62.133644 ]\n",
      " [ 2.2        1.340585  62.23938  ]\n",
      " [ 2.2        1.1188395 61.74905  ]\n",
      " [ 2.2        1.3425691 62.363537 ]]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "filepath= os.path.join('.','BO_data','predicted_optimums4.npyz')\n",
    "with open(filepath, 'rb') as file:\n",
    "    data = np.load(file)\n",
    "    values= data['values']\n",
    "    points= data['choices']\n",
    "\n",
    "print(values)\n",
    "print(points)\n",
    "print(len(values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
